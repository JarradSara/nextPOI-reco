{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84471e9-03dd-463a-86f0-a513cb6c165b",
   "metadata": {},
   "source": [
    "# Spark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c509aa-b0fb-4168-904b-c7bd71888ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import os\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "from scipy import spatial\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import radians, cos, sin, arcsin, sqrt\n",
    "from math import sin, cos, acos, radians, asin, sqrt\n",
    "from functools import reduce\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Phrases\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import findspark\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import split, col, udf, size, lit\n",
    "from pyspark.sql.types import StringType\n",
    "from urllib import request\n",
    "from IPython.core.magic import (register_line_magic, register_cell_magic, register_line_cell_magic)\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd77f72a-7c9d-4ff7-a8c3-c0b964178a58",
   "metadata": {
    "id": "f0831208-e728-4f85-b50d-75651eee8ca6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB de path\n"
     ]
    }
   ],
   "source": [
    "home = os.environ[\"HOME\"]\n",
    "\n",
    "D1 = \"/.local/lib/python3.9/site-packages/pyspark\"\n",
    "D2 = \"/root/anaconda3/lib/python3.9/site-packages/pyspark\"\n",
    "\n",
    "if os.path.exists(D1):\n",
    "    os.environ[\"SPARK_HOME\"] = home +  D1\n",
    "elif os.path.exists(D2):\n",
    "    os.environ[\"SPARK_HOME\"] = home +  D2\n",
    "else:\n",
    "    print(\"PB de path\")\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] =\"/usr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c833ccc6-aff5-4f29-92e8-0bc580258aef",
   "metadata": {
    "id": "13d58df7-7115-4475-bc47-c9fc2d37d691",
    "tags": []
   },
   "source": [
    "### Start spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9585f310-1bd8-433d-99d7-ba261c77775f",
   "metadata": {
    "id": "938e5846-9571-4a35-857a-ce5180a69c96",
    "outputId": "ea0cdf56-36c8-49f4-b887-6e7b3b6d3387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findspark.init() initialise les variables d'environnement pour spark\n"
     ]
    }
   ],
   "source": [
    "print(\"findspark.init() initialise les variables d'environnement pour spark\") \n",
    "findspark.init() \n",
    "\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de0163af-25f3-4980-8765-d413e09cecbc",
   "metadata": {
    "id": "68195c5c-7f29-46eb-9dcb-6e1ff39d0521",
    "outputId": "8cb3ab96-8d9e-4c69-eb87-b9548df690c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session démarrée, son id est  local-1682975293471\n"
     ]
    }
   ],
   "source": [
    "def demarrer_spark():\n",
    "    local = \"local[*]\"\n",
    "    appName = \"TP\"\n",
    "    configLocale = SparkConf().setAppName(appName).setMaster(local).\\\n",
    "    set(\"spark.executor.memory\", \"100G\").\\\n",
    "    set(\"spark.driver.memory\",\"50G\").\\\n",
    "    set(\"spark.sql.catalogImplementation\",\"in-memory\").\\\n",
    "    set(\"spark.driver.maxResultSize\", \"10G\")\n",
    "\n",
    "    spark = SparkSession.builder.config(conf = configLocale).getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "    # spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\",\"-1\")\n",
    "    # On ajuste l'environnement d'exécution des requêtes à la taille du cluster (4 coeurs)\n",
    "    # spark.conf.set(\"spark.sql.shuffle.partitions\",\"200\")    \n",
    "\n",
    "    print(\"session démarrée, son id est \", sc.applicationId)\n",
    "    return spark\n",
    "\n",
    "spark = demarrer_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f994dd5e-a29c-40e4-b69b-65c167606c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://json.lip6.fr:4046\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5d10290310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db507cee-d988-4782-a5ce-a1b8db322e67",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  SQL Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b68dd1a-29ad-4289-a6de-eac42436c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic, register_line_cell_magic)\n",
    "\n",
    "def removeComments(query):\n",
    "    result = \"\"\n",
    "    for line in query.split('\\n'):\n",
    "    if not(line.strip().startswith(\"--\")):\n",
    "        result += line + \"\\n\"\n",
    "    return result\n",
    "\n",
    "@register_line_cell_magic\n",
    "def sql(line, cell=None):\n",
    "    \"To run a sql query. Use:  %%sql\"\n",
    "    val = cell if cell is not None else line\n",
    "    tabRequetes = removeComments(val).split(\";\")\n",
    "    derniere = None\n",
    "    est_requete = False\n",
    "    for r in tabRequetes:\n",
    "        r = r.strip()\n",
    "        if len(r) > 2:\n",
    "          derniere = spark.sql(r)\n",
    "          est_requete = r.lower().startswith('select') or r.lower().startswith('with')  \n",
    "    if(est_requete):\n",
    "        return display(derniere)\n",
    "    else:\n",
    "        return print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecce597-8e26-43d5-8f0a-2b6c5e2396d4",
   "metadata": {},
   "source": [
    "display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e4f789c-c72b-4f51-bf47-349965a26f4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1648043826961,
     "user": {
      "displayName": "Hubert Naacke",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03575281438400116050"
     },
     "user_tz": -60
    },
    "id": "0b6a7db7-96d3-469d-89a9-eb30ccb7dfc0",
    "outputId": "e39d10eb-11a7-450c-cad1-4bb5c9c12f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display redéfini\n"
     ]
    }
   ],
   "source": [
    "def display(df, n=10):\n",
    "    pd.set_option('max_columns', None)\n",
    "    pd.set_option('max_colwidth', None)\n",
    "    return df.limit(n).toPandas()\n",
    "\n",
    "print(\"display redéfini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4749a-acd5-49b7-8b0b-27c5bbeba9a5",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "724eba1e-caf9-4436-b7ab-1dea89ad75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_dir: /local/jarrad/bd/\n",
      "model_dir: /local/jarrad/bd/model_dimension\n",
      "notebook_dir: /home/jarrad/Bureau/notebook_sara/\n",
      "experiment_dir: /home/jarrad/Bureau/notebook_sara/experiment/\n"
     ]
    }
   ],
   "source": [
    "class Parametre :\n",
    "    #Dataset storage URL\n",
    "    PUBLIC_DATASET_URL = \"https://nuage.lip6.fr/s/H3bpyRGgnCq2NR4\" \n",
    "\n",
    "\n",
    "    # Local directory\n",
    "    local_dir = \"/local/jarrad/bd/\"\n",
    "\n",
    "    # models storage directory\n",
    "    model_dir  = local_dir + \"model_dimension\"\n",
    "    model_name = model_dir + \"/model\" \n",
    "\n",
    "    yfcc_web_dir = \"YFCC_dataset_extrait\"\n",
    "    yfcc_file = \"yfccFrance\"\n",
    "    \n",
    "    \n",
    "    # Notebook Directory\n",
    "    notebook_dir = \"/home/jarrad/Bureau/notebook_sara/\"\n",
    "\n",
    "\n",
    "    # experiment_directory\n",
    "    experiment_dir = notebook_dir + \"experiment/\"\n",
    "\n",
    "\n",
    "    # parameters values chosen\n",
    "    maillage = [10, 40, 70, 150, 300]\n",
    "    expe_dimensions = [20, 25]\n",
    "    expe_topk = [15, 20]\n",
    "    expe_epochs = [100]\n",
    "    expe_windows = [5]\n",
    "   \n",
    "P = Parametre()\n",
    "print(\"local_dir:\", P.local_dir)\n",
    "print(\"model_dir:\", P.model_dir)\n",
    "print(\"notebook_dir:\", P.notebook_dir)\n",
    "print(\"experiment_dir:\", P.experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16fa19e3-2b99-4a17-9b1d-db1ad7693a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(P.local_dir, exist_ok=True)\n",
    "os.makedirs(P.model_dir, exist_ok=True)\n",
    "os.makedirs(P.experiment_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14330f4e-e225-4b4c-8666-e52d4b3cfdbd",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6067f749-5d30-4518-a53a-4b617d376449",
   "metadata": {
    "id": "09ec5ba0-b136-489c-a09b-4cc7482bc02f",
    "tags": []
   },
   "source": [
    "## Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5be4c533-47b9-4e36-b790-863212bc6e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_dimension',\n",
       " 'yfccFrance_M_40_trainset',\n",
       " 'yfccFrance_M_30_testset',\n",
       " 'yfccFrance_testset',\n",
       " 'yfccFrance_trainset.tgz',\n",
       " 'yfccFrance_testset.tgz',\n",
       " 'yfccFrance_M_100_testset',\n",
       " 'yfccFrance_M_70_trainset',\n",
       " 'yfccFrance_M_30_trainset',\n",
       " 'yfccFrance_M_1_trainset',\n",
       " 'yfccFrance_M_10_testset',\n",
       " 'yfccFrance_M_40_testset',\n",
       " 'yfccFrance_M_100_trainset',\n",
       " 'yfccFrance_M_1_testset',\n",
       " 'yfccFrance_M_70_testset',\n",
       " 'yfccFrance_M_5_trainset',\n",
       " 'yfccFrance_M_200_trainset',\n",
       " 'yfccFrance_M_150_testset',\n",
       " 'yfccFrance_M_5_testset',\n",
       " 'yfccFrance.zip',\n",
       " 'yfccFrance_M_400_trainset',\n",
       " 'yfccFrance_M_50_testset',\n",
       " 'yfccFrance_M_50_trainset',\n",
       " 'yfccFrance_M_500_trainset',\n",
       " 'yfccFrance_M_200_testset',\n",
       " 'yfccFrance_M_1e-07_trainset',\n",
       " 'yfccFrance_trainset',\n",
       " 'yfccFrance_M_1e-07_testset',\n",
       " 'yfccFrance_M_400_testset',\n",
       " 'yfccFrance_M_20_testset',\n",
       " 'yfccFrance_M_10_trainset',\n",
       " 'yfccFrance_M_20_trainset',\n",
       " 'yfccFrance_M_150_trainset',\n",
       " 'yfccFrance_M_500_testset',\n",
       " 'yfccFrance']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(P.local_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec06e1-cfb6-4c2e-bcad-aff8c235bd00",
   "metadata": {},
   "source": [
    "Fonction download file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6629cb6b-2272-435c-9b10-3ddb77fa9df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "définie\n"
     ]
    }
   ],
   "source": [
    "# download dataset if not already donwloaded\n",
    "def download_file(web_file, local_file):\n",
    "\n",
    "    if(os.path.isfile(local_file)):\n",
    "    print(local_file, \"is already stored\")\n",
    "    else:\n",
    "    print(\"downloading from URL: \", web_file , \"save in : \" + local_file)\n",
    "    request.urlretrieve(web_file , local_file)\n",
    "    \n",
    "print(\"définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde9f83-db16-4ea1-8130-7d1bda53d42f",
   "metadata": {},
   "source": [
    "URL to access to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fe7182-23b1-4c5f-81bc-8a2734c015a1",
   "metadata": {},
   "source": [
    "download YFCC file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad37b932-3182-44bf-97be-cace99e0f573",
   "metadata": {},
   "source": [
    "### YFCC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac58296f-efed-4185-a020-e1123ee517fc",
   "metadata": {},
   "source": [
    "### get_yfcc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beada459-90e9-4b8c-be00-2f2ace7e8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def get_yfcc_dataset(web_dir, local_dir, file):\n",
    "\n",
    "    local_file = local_dir + \"/\" + file\n",
    "    web_file = web_dir + \"/\" + file\n",
    "    download_file(web_file, local_file + \".zip\")\n",
    "\n",
    "    #unzip\n",
    "    if(os.path.isdir(local_file)):\n",
    "        print(\"file already unziped\")\n",
    "    else:\n",
    "      with zipfile.ZipFile(local_dir + \"/\" + file + \".zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(local_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d5967-ca6e-4d86-a875-3cdd64ff1c29",
   "metadata": {},
   "source": [
    "call get_yfcc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f4f9f61-bdef-4189-9919-d726b3ecb81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL du dossier contenant les datasets  https://nuage.lip6.fr/s/H3bpyRGgnCq2NR4\n",
      "/local/jarrad/bd//yfccFrance.zip is already stored\n",
      "file already unziped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_dimension',\n",
       " 'yfccFrance_M_40_trainset',\n",
       " 'yfccFrance_M_30_testset',\n",
       " 'yfccFrance_testset',\n",
       " 'yfccFrance_trainset.tgz',\n",
       " 'yfccFrance_testset.tgz',\n",
       " 'yfccFrance_M_100_testset',\n",
       " 'yfccFrance_M_70_trainset',\n",
       " 'yfccFrance_M_30_trainset',\n",
       " 'yfccFrance_M_1_trainset',\n",
       " 'yfccFrance_M_10_testset',\n",
       " 'yfccFrance_M_40_testset',\n",
       " 'yfccFrance_M_100_trainset',\n",
       " 'yfccFrance_M_1_testset',\n",
       " 'yfccFrance_M_70_testset',\n",
       " 'yfccFrance_M_5_trainset',\n",
       " 'yfccFrance_M_200_trainset',\n",
       " 'yfccFrance_M_150_testset',\n",
       " 'yfccFrance_M_5_testset',\n",
       " 'yfccFrance.zip',\n",
       " 'yfccFrance_M_400_trainset',\n",
       " 'yfccFrance_M_50_testset',\n",
       " 'yfccFrance_M_50_trainset',\n",
       " 'yfccFrance_M_500_trainset',\n",
       " 'yfccFrance_M_200_testset',\n",
       " 'yfccFrance_M_1e-07_trainset',\n",
       " 'yfccFrance_trainset',\n",
       " 'yfccFrance_M_1e-07_testset',\n",
       " 'yfccFrance_M_400_testset',\n",
       " 'yfccFrance_M_20_testset',\n",
       " 'yfccFrance_M_10_trainset',\n",
       " 'yfccFrance_M_20_trainset',\n",
       " 'yfccFrance_M_150_trainset',\n",
       " 'yfccFrance_M_500_testset',\n",
       " 'yfccFrance']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"URL du dossier contenant les datasets \", P.PUBLIC_DATASET_URL)\n",
    "\n",
    "yfcc_web_dir_download_URL = P.PUBLIC_DATASET_URL + \"/download?path=\" + \"/\" + P.yfcc_web_dir\n",
    "get_yfcc_dataset(yfcc_web_dir_download_URL , P.local_dir, P.yfcc_file)\n",
    "\n",
    "os.listdir(P.local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d05b75e8-b98a-4a0d-a862-fe87dc82ede3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>PhotoID</th>\n",
       "      <th>PhotoHash</th>\n",
       "      <th>UserNSID</th>\n",
       "      <th>UserNickname</th>\n",
       "      <th>DateTaken</th>\n",
       "      <th>DateUploaded</th>\n",
       "      <th>CaptureDevice</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>UserTags</th>\n",
       "      <th>MachineTags</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>URL</th>\n",
       "      <th>DownloadURL</th>\n",
       "      <th>LicenseName</th>\n",
       "      <th>LicenseURL</th>\n",
       "      <th>ServerID</th>\n",
       "      <th>FarmID</th>\n",
       "      <th>Secret</th>\n",
       "      <th>SecretOriginal</th>\n",
       "      <th>Extension</th>\n",
       "      <th>Marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80096796</td>\n",
       "      <td>834796</td>\n",
       "      <td>dc9b7584ecb34a448540bee3b38fe85c</td>\n",
       "      <td>77922700@N00</td>\n",
       "      <td>iko</td>\n",
       "      <td>2004-09-15 19:41:25.0</td>\n",
       "      <td>1097582515</td>\n",
       "      <td>PENTAX+Corporation+PENTAX+Optio+S4</td>\n",
       "      <td>marseille</td>\n",
       "      <td>None</td>\n",
       "      <td>city,cityproject,coucher+de+soleil,marseille,sunset,ville</td>\n",
       "      <td>None</td>\n",
       "      <td>5.371059</td>\n",
       "      <td>43.284172</td>\n",
       "      <td>16</td>\n",
       "      <td>http://www.flickr.com/photos/77922700@N00/834796/</td>\n",
       "      <td>http://farm1.staticflickr.com/1/834796_9e5d1edb3a.jpg</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivs License</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/2.0/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9e5d1edb3a</td>\n",
       "      <td>9e5d1edb3a</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64666153</td>\n",
       "      <td>5477598</td>\n",
       "      <td>4c38199a877fba534860a365bf9c97</td>\n",
       "      <td>76384935@N00</td>\n",
       "      <td>Chip_2904</td>\n",
       "      <td>2005-02-26 20:36:16.0</td>\n",
       "      <td>1109450176</td>\n",
       "      <td>None</td>\n",
       "      <td>Quiz+Night+2</td>\n",
       "      <td>None</td>\n",
       "      <td>france,lesarcs,skiing</td>\n",
       "      <td>None</td>\n",
       "      <td>6.832551</td>\n",
       "      <td>45.573586</td>\n",
       "      <td>13</td>\n",
       "      <td>http://www.flickr.com/photos/76384935@N00/5477598/</td>\n",
       "      <td>http://farm1.staticflickr.com/6/5477598_d4ec281653.jpg</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike License</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-sa/2.0/</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>d4ec281653</td>\n",
       "      <td>d4ec281653</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82397565</td>\n",
       "      <td>5975164</td>\n",
       "      <td>2a76868b7eb18ea240d48e2941648582</td>\n",
       "      <td>70408381@N00</td>\n",
       "      <td>scot2342</td>\n",
       "      <td>2004-07-31 10:12:52.0</td>\n",
       "      <td>1110087781</td>\n",
       "      <td>NIKON+E4200</td>\n",
       "      <td>Giverny</td>\n",
       "      <td>Giverny+flowers+Monet+France</td>\n",
       "      <td>2004,flowers,france,giverny,monet</td>\n",
       "      <td>None</td>\n",
       "      <td>1.524825</td>\n",
       "      <td>49.077106</td>\n",
       "      <td>16</td>\n",
       "      <td>http://www.flickr.com/photos/70408381@N00/5975164/</td>\n",
       "      <td>http://farm1.staticflickr.com/3/5975164_5ebb925aa1.jpg</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivs License</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/2.0/</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5ebb925aa1</td>\n",
       "      <td>5ebb925aa1</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39862899</td>\n",
       "      <td>8060056</td>\n",
       "      <td>987ba5ffd786949496eda3a5fcf89b2</td>\n",
       "      <td>32323502@N00</td>\n",
       "      <td>Julie70</td>\n",
       "      <td>2005-03-31 12:22:18.0</td>\n",
       "      <td>1112338974</td>\n",
       "      <td>SONY+DSC-P150</td>\n",
       "      <td>They+were+all+in+it</td>\n",
       "      <td>There+will+be+always+loving+couples+in+Paris%2C+kissing+each+other.+It+is+good+to+know...+even+if+it+is+no+more+me.+Between+Notre+Dame+and+the+Seine+there+is+a+quiet+alley.%0ASuddenly%2C+my+eyes+falled+on+this+couple%3A+they+were+all+in+the+kiss+and+the+embrace%2C+showing+the+love+and+tenderness+to+each+other.+%0A%0AThat+is+also+one+of+my+prefered+photos.+One+of+the+things+I+liked+most+were+her+sensible+shows+and+how+she+had+to+be+almost+on+tips+of+her+feet+to+arrive+to+him+and+how+much+reciprocity+showed+in+this+image+from+this+middle+aged+couple.%0A%0AI+remember%2C+looking+at+it%2C+as+probably+I+did+when+I+first+looked+at+it%2C+a+certain+night%2C+long+long+time+ago%3A+I+was+40+years+old%2C+and+my+husband+from+wich+I+was+separating+told+me+%22you+are+too+old%2C+no+one+would+want+you+any+more%22.%0A%0AI+met+an+intelligent+and+tender+American%2C+went+to+diner%2C+showing+him+later+%22Paris%22.+%0AA+night%2C+behind+Notre+Dame++I+discovered+I+can+be+regarded+as+woman+and+with+tenderness+again%2C+and+that+all+is+not+lost+as+I+believed+before.</td>\n",
       "      <td>1-5-fav,100+most+interesting,100+pages,120+of+50000,2,2005,a4,balade,best+in+22000,bigfavs,blog,choice,couples,deux,flickr+most+favorited,flickrfavs,for+valentine+day+2010,france,gens,images,julie+kertesz,julie70,kett%C3%B6,love,march,master%27s+prefered,mc%2307,mes+favoris,meschoix,most+interesting,mostfav,my+favorites,my+prefered,my+preferred,pair,paires,paris,paris+5e,paris+strolls,parisians,parisien,parisienne,parisiens,people,people+in+paris,personnages,photo+julie+kertesz,photo-pots,photography+julie+kertesz,photos,portrait,prefered,quais,rencontr%C3%A9s+%C3%A0+paris,rencontres,seine,someofmyfavorites,street+photo,stroll,tenderness,tendresse,three+years,together,top,top+favorited,top+interesting,topfavs,topvjulie70,two</td>\n",
       "      <td>None</td>\n",
       "      <td>2.346675</td>\n",
       "      <td>48.852306</td>\n",
       "      <td>14</td>\n",
       "      <td>http://www.flickr.com/photos/32323502@N00/8060056/</td>\n",
       "      <td>http://farm1.staticflickr.com/4/8060056_df5ed9e19b.jpg</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike License</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-sa/2.0/</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>df5ed9e19b</td>\n",
       "      <td>df5ed9e19b</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64976931</td>\n",
       "      <td>8916795</td>\n",
       "      <td>b1e9a0bbfd8a221830461d39a6c7e1d3</td>\n",
       "      <td>51035823282@N01</td>\n",
       "      <td>alexdecarvalho</td>\n",
       "      <td>2005-04-08 17:56:02.0</td>\n",
       "      <td>1113079413</td>\n",
       "      <td>Canon+DIGITAL+IXUS+40</td>\n",
       "      <td>Grupo+Corpo</td>\n",
       "      <td>None</td>\n",
       "      <td>2005,brasil,brazil,dance,france,francebrazil,grupocorpo,paris</td>\n",
       "      <td>None</td>\n",
       "      <td>2.304210</td>\n",
       "      <td>48.866394</td>\n",
       "      <td>15</td>\n",
       "      <td>http://www.flickr.com/photos/51035823282@N01/8916795/</td>\n",
       "      <td>http://farm1.staticflickr.com/8/8916795_11c551a24b.jpg</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike License</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-sa/2.0/</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11c551a24b</td>\n",
       "      <td>11c551a24b</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82227190</td>\n",
       "      <td>9785366</td>\n",
       "      <td>7a4fad34c5724a9b92715e64ef81e5e</td>\n",
       "      <td>57366077@N00</td>\n",
       "      <td>j.s.+clark</td>\n",
       "      <td>2005-03-17 01:18:20.0</td>\n",
       "      <td>1113841862</td>\n",
       "      <td>NIKON+E4300</td>\n",
       "      <td>DSCN3782</td>\n",
       "      <td>Street+of+pushy+Greek+restaurateurs+%28Rue+de+la+Huchette%29.++%22Ey%2C+you+want+French%3F++French+is+here%21%21%22++This+was+sooo+tourist-thronged+it+made+me+long+for+rue+Lepic+or+even+rue+Cler.++Sounds+snobby%2C+but+what+a+difference.++This+looked+like+Duval+Street+in+Key+West.</td>\n",
       "      <td>france,paris</td>\n",
       "      <td>None</td>\n",
       "      <td>2.348333</td>\n",
       "      <td>48.852177</td>\n",
       "      <td>16</td>\n",
       "      <td>http://www.flickr.com/photos/57366077@N00/9785366/</td>\n",
       "      <td>http://farm1.staticflickr.com/4/9785366_975272aa42.jpg</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike License</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-sa/2.0/</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>975272aa42</td>\n",
       "      <td>975272aa42</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80027775</td>\n",
       "      <td>15258293</td>\n",
       "      <td>abde63262e9157be4bea5e34c797b6c6</td>\n",
       "      <td>70786516@N00</td>\n",
       "      <td>jmm403</td>\n",
       "      <td>2005-05-23 12:49:13.0</td>\n",
       "      <td>1116845353</td>\n",
       "      <td>None</td>\n",
       "      <td>Les+mouleurs+d%C3%A9moulent+-+3</td>\n",
       "      <td>Quand+les+stagiaires+investissent+les+lieux+...</td>\n",
       "      <td>france,home,installation,nature,plaze1d4e820be705d62083b3c2a0d581cb4c,plazes,setup</td>\n",
       "      <td>None</td>\n",
       "      <td>1.783304</td>\n",
       "      <td>47.866096</td>\n",
       "      <td>16</td>\n",
       "      <td>http://www.flickr.com/photos/70786516@N00/15258293/</td>\n",
       "      <td>http://farm1.staticflickr.com/9/15258293_21ad650046.jpg</td>\n",
       "      <td>Attribution-NonCommercial-NoDerivs License</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-nd/2.0/</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>21ad650046</td>\n",
       "      <td>21ad650046</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75639873</td>\n",
       "      <td>15470300</td>\n",
       "      <td>348ee7682fea23977eec8b1e3bf1</td>\n",
       "      <td>77357393@N00</td>\n",
       "      <td>muckster</td>\n",
       "      <td>2002-09-19 00:00:00.0</td>\n",
       "      <td>1116944075</td>\n",
       "      <td>NIKON+E900</td>\n",
       "      <td>Bubble+House</td>\n",
       "      <td>None</td>\n",
       "      <td>cotedazur,france,mediterranean,riviera,rock,sea,villa,water</td>\n",
       "      <td>None</td>\n",
       "      <td>7.076911</td>\n",
       "      <td>43.576412</td>\n",
       "      <td>10</td>\n",
       "      <td>http://www.flickr.com/photos/77357393@N00/15470300/</td>\n",
       "      <td>http://farm1.staticflickr.com/13/15470300_2dbe9d8196.jpg</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike License</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-sa/2.0/</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2dbe9d8196</td>\n",
       "      <td>2dbe9d8196</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>69533974</td>\n",
       "      <td>16396565</td>\n",
       "      <td>e4cf846d4386b53834c4c9ba9326fd</td>\n",
       "      <td>49691054@N00</td>\n",
       "      <td>Alexandre+Gacon</td>\n",
       "      <td>2005-04-02 16:32:55.0</td>\n",
       "      <td>1117445508</td>\n",
       "      <td>SONY+DSC-W1</td>\n",
       "      <td>DSC00906</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.864540</td>\n",
       "      <td>49.547153</td>\n",
       "      <td>12</td>\n",
       "      <td>http://www.flickr.com/photos/49691054@N00/16396565/</td>\n",
       "      <td>http://farm1.staticflickr.com/14/16396565_a3f3d22780.jpg</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike License</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-sa/2.0/</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>a3f3d22780</td>\n",
       "      <td>a3f3d22780</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86822392</td>\n",
       "      <td>17251304</td>\n",
       "      <td>3a65da8bd69dea534ad40271e3e5352</td>\n",
       "      <td>49691054@N00</td>\n",
       "      <td>Alexandre+Gacon</td>\n",
       "      <td>2005-05-17 15:46:50.0</td>\n",
       "      <td>1117820724</td>\n",
       "      <td>SONY+DSC-W1</td>\n",
       "      <td>DSC01407</td>\n",
       "      <td>None</td>\n",
       "      <td>france,lot,paysage,saintcirqlapopie</td>\n",
       "      <td>None</td>\n",
       "      <td>1.670951</td>\n",
       "      <td>44.466560</td>\n",
       "      <td>12</td>\n",
       "      <td>http://www.flickr.com/photos/49691054@N00/17251304/</td>\n",
       "      <td>http://farm1.staticflickr.com/11/17251304_af9b8de102.jpg</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike License</td>\n",
       "      <td>http://creativecommons.org/licenses/by-nc-sa/2.0/</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>af9b8de102</td>\n",
       "      <td>af9b8de102</td>\n",
       "      <td>jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Line   PhotoID                         PhotoHash         UserNSID  \\\n",
       "0  80096796    834796  dc9b7584ecb34a448540bee3b38fe85c     77922700@N00   \n",
       "1  64666153   5477598    4c38199a877fba534860a365bf9c97     76384935@N00   \n",
       "2  82397565   5975164  2a76868b7eb18ea240d48e2941648582     70408381@N00   \n",
       "3  39862899   8060056   987ba5ffd786949496eda3a5fcf89b2     32323502@N00   \n",
       "4  64976931   8916795  b1e9a0bbfd8a221830461d39a6c7e1d3  51035823282@N01   \n",
       "5  82227190   9785366   7a4fad34c5724a9b92715e64ef81e5e     57366077@N00   \n",
       "6  80027775  15258293  abde63262e9157be4bea5e34c797b6c6     70786516@N00   \n",
       "7  75639873  15470300      348ee7682fea23977eec8b1e3bf1     77357393@N00   \n",
       "8  69533974  16396565    e4cf846d4386b53834c4c9ba9326fd     49691054@N00   \n",
       "9  86822392  17251304   3a65da8bd69dea534ad40271e3e5352     49691054@N00   \n",
       "\n",
       "      UserNickname              DateTaken  DateUploaded  \\\n",
       "0              iko  2004-09-15 19:41:25.0    1097582515   \n",
       "1        Chip_2904  2005-02-26 20:36:16.0    1109450176   \n",
       "2         scot2342  2004-07-31 10:12:52.0    1110087781   \n",
       "3          Julie70  2005-03-31 12:22:18.0    1112338974   \n",
       "4   alexdecarvalho  2005-04-08 17:56:02.0    1113079413   \n",
       "5       j.s.+clark  2005-03-17 01:18:20.0    1113841862   \n",
       "6           jmm403  2005-05-23 12:49:13.0    1116845353   \n",
       "7         muckster  2002-09-19 00:00:00.0    1116944075   \n",
       "8  Alexandre+Gacon  2005-04-02 16:32:55.0    1117445508   \n",
       "9  Alexandre+Gacon  2005-05-17 15:46:50.0    1117820724   \n",
       "\n",
       "                        CaptureDevice                            Title  \\\n",
       "0  PENTAX+Corporation+PENTAX+Optio+S4                        marseille   \n",
       "1                                None                     Quiz+Night+2   \n",
       "2                         NIKON+E4200                          Giverny   \n",
       "3                       SONY+DSC-P150              They+were+all+in+it   \n",
       "4               Canon+DIGITAL+IXUS+40                      Grupo+Corpo   \n",
       "5                         NIKON+E4300                         DSCN3782   \n",
       "6                                None  Les+mouleurs+d%C3%A9moulent+-+3   \n",
       "7                          NIKON+E900                     Bubble+House   \n",
       "8                         SONY+DSC-W1                         DSC00906   \n",
       "9                         SONY+DSC-W1                         DSC01407   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Description  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           None   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           None   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Giverny+flowers+Monet+France   \n",
       "3  There+will+be+always+loving+couples+in+Paris%2C+kissing+each+other.+It+is+good+to+know...+even+if+it+is+no+more+me.+Between+Notre+Dame+and+the+Seine+there+is+a+quiet+alley.%0ASuddenly%2C+my+eyes+falled+on+this+couple%3A+they+were+all+in+the+kiss+and+the+embrace%2C+showing+the+love+and+tenderness+to+each+other.+%0A%0AThat+is+also+one+of+my+prefered+photos.+One+of+the+things+I+liked+most+were+her+sensible+shows+and+how+she+had+to+be+almost+on+tips+of+her+feet+to+arrive+to+him+and+how+much+reciprocity+showed+in+this+image+from+this+middle+aged+couple.%0A%0AI+remember%2C+looking+at+it%2C+as+probably+I+did+when+I+first+looked+at+it%2C+a+certain+night%2C+long+long+time+ago%3A+I+was+40+years+old%2C+and+my+husband+from+wich+I+was+separating+told+me+%22you+are+too+old%2C+no+one+would+want+you+any+more%22.%0A%0AI+met+an+intelligent+and+tender+American%2C+went+to+diner%2C+showing+him+later+%22Paris%22.+%0AA+night%2C+behind+Notre+Dame++I+discovered+I+can+be+regarded+as+woman+and+with+tenderness+again%2C+and+that+all+is+not+lost+as+I+believed+before.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           None   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Street+of+pushy+Greek+restaurateurs+%28Rue+de+la+Huchette%29.++%22Ey%2C+you+want+French%3F++French+is+here%21%21%22++This+was+sooo+tourist-thronged+it+made+me+long+for+rue+Lepic+or+even+rue+Cler.++Sounds+snobby%2C+but+what+a+difference.++This+looked+like+Duval+Street+in+Key+West.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Quand+les+stagiaires+investissent+les+lieux+...   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           None   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           None   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         UserTags  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       city,cityproject,coucher+de+soleil,marseille,sunset,ville   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           france,lesarcs,skiing   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               2004,flowers,france,giverny,monet   \n",
       "3  1-5-fav,100+most+interesting,100+pages,120+of+50000,2,2005,a4,balade,best+in+22000,bigfavs,blog,choice,couples,deux,flickr+most+favorited,flickrfavs,for+valentine+day+2010,france,gens,images,julie+kertesz,julie70,kett%C3%B6,love,march,master%27s+prefered,mc%2307,mes+favoris,meschoix,most+interesting,mostfav,my+favorites,my+prefered,my+preferred,pair,paires,paris,paris+5e,paris+strolls,parisians,parisien,parisienne,parisiens,people,people+in+paris,personnages,photo+julie+kertesz,photo-pots,photography+julie+kertesz,photos,portrait,prefered,quais,rencontr%C3%A9s+%C3%A0+paris,rencontres,seine,someofmyfavorites,street+photo,stroll,tenderness,tendresse,three+years,together,top,top+favorited,top+interesting,topfavs,topvjulie70,two   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2005,brasil,brazil,dance,france,francebrazil,grupocorpo,paris   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    france,paris   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              france,home,installation,nature,plaze1d4e820be705d62083b3c2a0d581cb4c,plazes,setup   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     cotedazur,france,mediterranean,riviera,rock,sea,villa,water   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            None   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             france,lot,paysage,saintcirqlapopie   \n",
       "\n",
       "  MachineTags  Longitude   Latitude  Accuracy  \\\n",
       "0        None   5.371059  43.284172        16   \n",
       "1        None   6.832551  45.573586        13   \n",
       "2        None   1.524825  49.077106        16   \n",
       "3        None   2.346675  48.852306        14   \n",
       "4        None   2.304210  48.866394        15   \n",
       "5        None   2.348333  48.852177        16   \n",
       "6        None   1.783304  47.866096        16   \n",
       "7        None   7.076911  43.576412        10   \n",
       "8        None   4.864540  49.547153        12   \n",
       "9        None   1.670951  44.466560        12   \n",
       "\n",
       "                                                     URL  \\\n",
       "0      http://www.flickr.com/photos/77922700@N00/834796/   \n",
       "1     http://www.flickr.com/photos/76384935@N00/5477598/   \n",
       "2     http://www.flickr.com/photos/70408381@N00/5975164/   \n",
       "3     http://www.flickr.com/photos/32323502@N00/8060056/   \n",
       "4  http://www.flickr.com/photos/51035823282@N01/8916795/   \n",
       "5     http://www.flickr.com/photos/57366077@N00/9785366/   \n",
       "6    http://www.flickr.com/photos/70786516@N00/15258293/   \n",
       "7    http://www.flickr.com/photos/77357393@N00/15470300/   \n",
       "8    http://www.flickr.com/photos/49691054@N00/16396565/   \n",
       "9    http://www.flickr.com/photos/49691054@N00/17251304/   \n",
       "\n",
       "                                                DownloadURL  \\\n",
       "0     http://farm1.staticflickr.com/1/834796_9e5d1edb3a.jpg   \n",
       "1    http://farm1.staticflickr.com/6/5477598_d4ec281653.jpg   \n",
       "2    http://farm1.staticflickr.com/3/5975164_5ebb925aa1.jpg   \n",
       "3    http://farm1.staticflickr.com/4/8060056_df5ed9e19b.jpg   \n",
       "4    http://farm1.staticflickr.com/8/8916795_11c551a24b.jpg   \n",
       "5    http://farm1.staticflickr.com/4/9785366_975272aa42.jpg   \n",
       "6   http://farm1.staticflickr.com/9/15258293_21ad650046.jpg   \n",
       "7  http://farm1.staticflickr.com/13/15470300_2dbe9d8196.jpg   \n",
       "8  http://farm1.staticflickr.com/14/16396565_a3f3d22780.jpg   \n",
       "9  http://farm1.staticflickr.com/11/17251304_af9b8de102.jpg   \n",
       "\n",
       "                                    LicenseName  \\\n",
       "0    Attribution-NonCommercial-NoDerivs License   \n",
       "1  Attribution-NonCommercial-ShareAlike License   \n",
       "2    Attribution-NonCommercial-NoDerivs License   \n",
       "3  Attribution-NonCommercial-ShareAlike License   \n",
       "4  Attribution-NonCommercial-ShareAlike License   \n",
       "5  Attribution-NonCommercial-ShareAlike License   \n",
       "6    Attribution-NonCommercial-NoDerivs License   \n",
       "7  Attribution-NonCommercial-ShareAlike License   \n",
       "8  Attribution-NonCommercial-ShareAlike License   \n",
       "9  Attribution-NonCommercial-ShareAlike License   \n",
       "\n",
       "                                          LicenseURL  ServerID  FarmID  \\\n",
       "0  http://creativecommons.org/licenses/by-nc-nd/2.0/         1       1   \n",
       "1  http://creativecommons.org/licenses/by-nc-sa/2.0/         6       1   \n",
       "2  http://creativecommons.org/licenses/by-nc-nd/2.0/         3       1   \n",
       "3  http://creativecommons.org/licenses/by-nc-sa/2.0/         4       1   \n",
       "4  http://creativecommons.org/licenses/by-nc-sa/2.0/         8       1   \n",
       "5  http://creativecommons.org/licenses/by-nc-sa/2.0/         4       1   \n",
       "6  http://creativecommons.org/licenses/by-nc-nd/2.0/         9       1   \n",
       "7  http://creativecommons.org/licenses/by-nc-sa/2.0/        13       1   \n",
       "8  http://creativecommons.org/licenses/by-nc-sa/2.0/        14       1   \n",
       "9  http://creativecommons.org/licenses/by-nc-sa/2.0/        11       1   \n",
       "\n",
       "       Secret SecretOriginal Extension  Marker  \n",
       "0  9e5d1edb3a     9e5d1edb3a       jpg       0  \n",
       "1  d4ec281653     d4ec281653       jpg       0  \n",
       "2  5ebb925aa1     5ebb925aa1       jpg       0  \n",
       "3  df5ed9e19b     df5ed9e19b       jpg       0  \n",
       "4  11c551a24b     11c551a24b       jpg       0  \n",
       "5  975272aa42     975272aa42       jpg       0  \n",
       "6  21ad650046     21ad650046       jpg       0  \n",
       "7  2dbe9d8196     2dbe9d8196       jpg       0  \n",
       "8  a3f3d22780     a3f3d22780       jpg       0  \n",
       "9  af9b8de102     af9b8de102       jpg       0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lire_yfcc(nom_fichier):\n",
    "    #local_dir = \"/data/bd/jarrad/\"\n",
    "    local_dir = \"/local/jarrad/bd\"\n",
    "    res = spark.read.parquet(local_dir + \"/\" + nom_fichier).persist()\n",
    "    return res\n",
    "\n",
    "yfcc = lire_yfcc(P.yfcc_file)\n",
    "display(yfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ac659-7166-424f-bba5-885650d6ed2c",
   "metadata": {},
   "source": [
    "### Visits table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebdf98dd-2098-40f3-9a39-1d8fe3066f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visite(yfcc):\n",
    "    yfcc.createOrReplaceTempView(\"YFCC\")\n",
    "    visite = \"\"\"\n",
    "    select photoID as photo, userNSID as user, timestamp(datetaken) as datetime, date(datetaken) as jour, latitude, longitude,  concat(round(latitude,4), '-', round(longitude,4)) as gridID\n",
    "    from YFCC\n",
    "    \"\"\"\n",
    "    return spark.sql(visite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e1e8dc8-dea5-4fe2-adfe-4f3d9a9aa52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo</th>\n",
       "      <th>user</th>\n",
       "      <th>datetime</th>\n",
       "      <th>jour</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>gridID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834796</td>\n",
       "      <td>77922700@N00</td>\n",
       "      <td>2004-09-15 19:41:25</td>\n",
       "      <td>2004-09-15</td>\n",
       "      <td>43.284172</td>\n",
       "      <td>5.371059</td>\n",
       "      <td>43.2842-5.3711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5477598</td>\n",
       "      <td>76384935@N00</td>\n",
       "      <td>2005-02-26 20:36:16</td>\n",
       "      <td>2005-02-26</td>\n",
       "      <td>45.573586</td>\n",
       "      <td>6.832551</td>\n",
       "      <td>45.5736-6.8326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5975164</td>\n",
       "      <td>70408381@N00</td>\n",
       "      <td>2004-07-31 10:12:52</td>\n",
       "      <td>2004-07-31</td>\n",
       "      <td>49.077106</td>\n",
       "      <td>1.524825</td>\n",
       "      <td>49.0771-1.5248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8060056</td>\n",
       "      <td>32323502@N00</td>\n",
       "      <td>2005-03-31 12:22:18</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>48.852306</td>\n",
       "      <td>2.346675</td>\n",
       "      <td>48.8523-2.3467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8916795</td>\n",
       "      <td>51035823282@N01</td>\n",
       "      <td>2005-04-08 17:56:02</td>\n",
       "      <td>2005-04-08</td>\n",
       "      <td>48.866394</td>\n",
       "      <td>2.304210</td>\n",
       "      <td>48.8664-2.3042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9785366</td>\n",
       "      <td>57366077@N00</td>\n",
       "      <td>2005-03-17 01:18:20</td>\n",
       "      <td>2005-03-17</td>\n",
       "      <td>48.852177</td>\n",
       "      <td>2.348333</td>\n",
       "      <td>48.8522-2.3483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15258293</td>\n",
       "      <td>70786516@N00</td>\n",
       "      <td>2005-05-23 12:49:13</td>\n",
       "      <td>2005-05-23</td>\n",
       "      <td>47.866096</td>\n",
       "      <td>1.783304</td>\n",
       "      <td>47.8661-1.7833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15470300</td>\n",
       "      <td>77357393@N00</td>\n",
       "      <td>2002-09-19 00:00:00</td>\n",
       "      <td>2002-09-19</td>\n",
       "      <td>43.576412</td>\n",
       "      <td>7.076911</td>\n",
       "      <td>43.5764-7.0769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16396565</td>\n",
       "      <td>49691054@N00</td>\n",
       "      <td>2005-04-02 16:32:55</td>\n",
       "      <td>2005-04-02</td>\n",
       "      <td>49.547153</td>\n",
       "      <td>4.864540</td>\n",
       "      <td>49.5472-4.8645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17251304</td>\n",
       "      <td>49691054@N00</td>\n",
       "      <td>2005-05-17 15:46:50</td>\n",
       "      <td>2005-05-17</td>\n",
       "      <td>44.466560</td>\n",
       "      <td>1.670951</td>\n",
       "      <td>44.4666-1.671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      photo             user            datetime        jour   latitude  \\\n",
       "0    834796     77922700@N00 2004-09-15 19:41:25  2004-09-15  43.284172   \n",
       "1   5477598     76384935@N00 2005-02-26 20:36:16  2005-02-26  45.573586   \n",
       "2   5975164     70408381@N00 2004-07-31 10:12:52  2004-07-31  49.077106   \n",
       "3   8060056     32323502@N00 2005-03-31 12:22:18  2005-03-31  48.852306   \n",
       "4   8916795  51035823282@N01 2005-04-08 17:56:02  2005-04-08  48.866394   \n",
       "5   9785366     57366077@N00 2005-03-17 01:18:20  2005-03-17  48.852177   \n",
       "6  15258293     70786516@N00 2005-05-23 12:49:13  2005-05-23  47.866096   \n",
       "7  15470300     77357393@N00 2002-09-19 00:00:00  2002-09-19  43.576412   \n",
       "8  16396565     49691054@N00 2005-04-02 16:32:55  2005-04-02  49.547153   \n",
       "9  17251304     49691054@N00 2005-05-17 15:46:50  2005-05-17  44.466560   \n",
       "\n",
       "   longitude          gridID  \n",
       "0   5.371059  43.2842-5.3711  \n",
       "1   6.832551  45.5736-6.8326  \n",
       "2   1.524825  49.0771-1.5248  \n",
       "3   2.346675  48.8523-2.3467  \n",
       "4   2.304210  48.8664-2.3042  \n",
       "5   2.348333  48.8522-2.3483  \n",
       "6   1.783304  47.8661-1.7833  \n",
       "7   7.076911  43.5764-7.0769  \n",
       "8   4.864540  49.5472-4.8645  \n",
       "9   1.670951   44.4666-1.671  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visite1 = visite(yfcc)\n",
    "display(visite1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b55164-89dd-424d-8de4-9fc2e102dfa2",
   "metadata": {},
   "source": [
    "### VisiteRound(n)\n",
    "Function specifying the mesh size used in a number n of meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9971b809-3c18-4d5d-8a84-6aa9854fb883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.round_to_n_meters(degree_coordinate, n)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def round_to_n_meters(degree_coordinate, n):\n",
    "    # Approximate number of meters for 1 degree close to the equator\n",
    "    meters = degree_coordinate * 111319.9\n",
    "    rounded_meters = round(meters / n) * n\n",
    "    as_degree = rounded_meters / 111319.9\n",
    "    return as_degree\n",
    "\n",
    "spark.udf.register(\"round_to_n_meters\", round_to_n_meters, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54469d29-5331-4ed4-80ed-7d313c8bb604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit_round_to_n_meters(visite, n):\n",
    "    visite.createOrReplaceTempView(\"visite\")\n",
    "    query = f\"\"\"\n",
    "            select user, jour, datetime, round_to_n_meters(latitude, {n}) as latitude , round_to_n_meters(longitude, {n}) as longitude\n",
    "            from visite\n",
    "            order by latitude, longitude;\n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e486177-c4e9-4cc7-94c3-8b4ecb3eb1da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### POIs in France"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a29465-07b2-4498-a63a-e29fa42a5c9f",
   "metadata": {},
   "source": [
    "#### distinct latitudes, longitudes in the dataset, and their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8944fa46-c74c-4d56-802d-1f770a7c2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_long_freq(visite_round3):\n",
    "    visite_round3.createOrReplaceTempView(\"Visite_Round\")\n",
    "    query = \"\"\"\n",
    "            select latitude, longitude, count(*) as freq\n",
    "            from Visite_Round\n",
    "            group by latitude, longitude\n",
    "            order by freq desc        \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6543d37d-ee45-4995-86ff-65ec1850607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_France(table_LatLongFrance):\n",
    "    table_LatLongFrance.createOrReplaceTempView(\"LatLongFrance\")\n",
    "    query = \"\"\"\n",
    "            select * \n",
    "            from LatLongFrance\n",
    "            where latitude between  41.29097926752132 and 51.4708053796387\n",
    "            and longitude between  -6.04365244747813 and 9.8145023996386\n",
    "            ;\n",
    "            \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22803d97-885e-4376-8416-d9336e96c5e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### numbering the POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b289693f-9e9c-49d2-9abc-6d239b837f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numorer_POI(latLongFrance):\n",
    "    latLongFrance.createOrReplaceTempView(\"numPOI\")\n",
    "    query = \"\"\"\n",
    "            select  latitude, longitude, row_number() over (order by latitude, longitude) as num\n",
    "            from numPOI\n",
    "            order by latitude, longitude\n",
    "            ;\n",
    "            \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9d61b-3fed-444f-b6ac-02d2178d9989",
   "metadata": {},
   "source": [
    "### Initial set with POI numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "976a39ad-b80f-4542-bf7d-46de6c4e2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visiteNum(table_numPOI, table_visiteRound3):\n",
    "    table_numPOI.createOrReplaceTempView(\"numPOII\")\n",
    "    table_visiteRound3.createOrReplaceTempView(\"VisiteRoundd3\")\n",
    "    \n",
    "    query = \"\"\"\n",
    "            select v.*, n.num\n",
    "            from VisiteRoundd3 v, numPOII n\n",
    "            where v.latitude = n.latitude and v.longitude = n.longitude;\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff10cb-7584-4d53-b088-0d0970bff91d",
   "metadata": {},
   "source": [
    "### Trajectories construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7747d44d-fb32-4f25-a938-d36d77f69a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_trajectoires(listeCouples)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_trajectoires (listeCouples):\n",
    "    listeCouples.sort()\n",
    "    liste_poi = [poi for d,poi in listeCouples]\n",
    "    return get_trajectoires_V3(liste_poi)\n",
    "\n",
    "\n",
    "def get_trajectoires_V3(liste_poi):    \n",
    "    results = []\n",
    "    result = []\n",
    "    for poi in liste_poi:\n",
    "        if len(result)==0: \n",
    "            result.append(poi)\n",
    "        elif result[-1] != poi: \n",
    "            if not poi in result:\n",
    "                result.append(poi)\n",
    "            else:\n",
    "                if len(result)>1:\n",
    "                    results.append(result)\n",
    "                result = [poi]\n",
    "    if len(result)>1:    \n",
    "        results.append(result) \n",
    "    return results\n",
    "\n",
    "spark.udf.register(\"get_trajectoires\", get_trajectoires, ArrayType(ArrayType(IntegerType())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b159a39b-d63a-418b-a5cb-a508ffef3383",
   "metadata": {},
   "source": [
    "#### All trajectory sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae7872-022b-453a-8d9e-5d534feba026",
   "metadata": {},
   "source": [
    "We limit ourselves to trajectories with a SIZE >=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce4ee91e-5c60-49fa-8dbc-b2cb61bd308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toutes_tailles_trajectoires(table_visites):\n",
    "    table_visites.createOrReplaceTempView(\"trajectoires_toutes_taille\")\n",
    "    query = \"\"\"\n",
    "            select user, jour, explode(get_trajectoires(collect_list( (to_unix_timestamp(datetime), num)))) as trajectoire\n",
    "            from trajectoires_toutes_taille\n",
    "            group by user, jour;\n",
    "            \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a9f42b-efa8-42bf-8da2-c1c5e6684627",
   "metadata": {},
   "source": [
    "#### Trajectories with size >=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1325d61f-b24d-49a6-b9f4-647b4c52101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectoires_sup3(table_traj_toutes_tailles):\n",
    "    table_traj_toutes_tailles.createOrReplaceTempView(\"trajectoires\")\n",
    "    query = \"\"\"\n",
    "            select *\n",
    "            from trajectoires\n",
    "            where where size(trajectoire) >=3\n",
    "            order by user,jour;\n",
    "            \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84934b9-c9b3-4fa0-8121-2fb46fb4142a",
   "metadata": {},
   "source": [
    "### train/test construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf7ff0-9afa-4715-8bd6-ebd796402911",
   "metadata": {},
   "source": [
    "#### Create test trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef34874-94eb-490f-ae30-06b6022a50e7",
   "metadata": {},
   "source": [
    "Avoid cold start: \n",
    "\n",
    "Eligibility: a test set is created such that for each trajectory, there is at least another one that has the same 2 last POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c42fc61c-d72c-4143-9954-6b08f3fe1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectoire_eligible(table_traj_sup_3):\n",
    "    table_traj_sup_3.createOrReplaceTempView(\"table_traj_sup_3\")\n",
    "    query = \"\"\"\n",
    "            select DISTINCT t1.trajectoire, t1.user, t1.jour, element_at(t1.trajectoire, -2) as avant_dernier_poi, element_at(t1.trajectoire, -1) as dernier_poi\n",
    "            from table_traj_sup_3 t1, table_traj_sup_3 t2\n",
    "            where element_at(t1.trajectoire, -2) = element_at(t2.trajectoire, -2) \n",
    "            and element_at(t1.trajectoire, -1) = element_at(t2.trajectoire, -1) \n",
    "            and t1.trajectoire <> t2.trajectoire\n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6042d-9952-4422-a4a7-210c3cd623c7",
   "metadata": {},
   "source": [
    "##### Total number of eligible test trajectories for all meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8904e41-ff31-4055-9b9b-9ffa415f8b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maillage</th>\n",
       "      <th>nombre_poi_france</th>\n",
       "      <th>nombre_trajectoire_eligible</th>\n",
       "      <th>longueur_moyenne_seq_par_maillage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>473296</td>\n",
       "      <td>503</td>\n",
       "      <td>4.972167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>326923</td>\n",
       "      <td>1987</td>\n",
       "      <td>6.240060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>266331</td>\n",
       "      <td>4133</td>\n",
       "      <td>6.058553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>194579</td>\n",
       "      <td>8982</td>\n",
       "      <td>5.409820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>142211</td>\n",
       "      <td>14064</td>\n",
       "      <td>4.771758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maillage  nombre_poi_france  nombre_trajectoire_eligible  \\\n",
       "0        10             473296                          503   \n",
       "1        40             326923                         1987   \n",
       "2        70             266331                         4133   \n",
       "3       150             194579                         8982   \n",
       "4       300             142211                        14064   \n",
       "\n",
       "   longueur_moyenne_seq_par_maillage  \n",
       "0                           4.972167  \n",
       "1                           6.240060  \n",
       "2                           6.058553  \n",
       "3                           5.409820  \n",
       "4                           4.771758  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_toutes_valeurs_compt = []\n",
    "for n in P.maillage:\n",
    "    yfcc = lire_yfcc(P.yfcc_file)\n",
    "    visite1 = visite(yfcc)\n",
    "    visiteRound = visit_round_to_n_meters(visite1, n)\n",
    "    frequence = lat_long_freq(visiteRound)\n",
    "    latlongFrance = bounding_box_France(frequence)\n",
    "    table_avec_num_POI = numorer_POI(latlongFrance)\n",
    "    table_visite_avec_num_POI = visiteNum(table_avec_num_POI, visiteRound)\n",
    "    traj_toutes_tailles = toutes_tailles_trajectoires(table_visite_avec_num_POI)\n",
    "    trajectoires_superieur_3 = trajectoires_sup3(traj_toutes_tailles)\n",
    "    \n",
    "    trajectoires_eligibles = trajectoire_eligible(trajectoires_superieur_3)\n",
    "    nombre_trajectoire_eligible = trajectoires_eligibles.count()\n",
    "    \n",
    "    longueur_moyenne_traj_eligible = (trajectoires_eligibles.select(\"trajectoire\").withColumn(\"longueur\", f.size(\"trajectoire\"))).agg(f.avg(\"longueur\").alias(\"longueur_moyenne\"))\n",
    "    longueur_moyenne_traj_eligible_pandas = longueur_moyenne_traj_eligible.toPandas()\n",
    "    longueur_moyenne_par_maillage = longueur_moyenne_traj_eligible_pandas[\"longueur_moyenne\"][0]\n",
    "    nombre_poi_france = latlongFrance.count()\n",
    "    \n",
    "    \n",
    "    tuple_taille_traj_par_maillage = (n, nombre_poi_france, nombre_trajectoire_eligible, longueur_moyenne_par_maillage)\n",
    "    liste_toutes_valeurs_compt.append(tuple_taille_traj_par_maillage)\n",
    "    \n",
    "columns=['maillage', 'nombre_poi_france', 'nombre_trajectoire_eligible', 'longueur_moyenne_seq_par_maillage'] \n",
    "nbr_traj_eligible = pd.DataFrame(liste_toutes_valeurs_compt, columns = columns)\n",
    "nbr_traj_eligible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd221e0-0178-4969-b8d5-936ce55484a6",
   "metadata": {},
   "source": [
    "sort by date the trajectories that have the same suffix and number them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "97fed2b3-e070-4a5f-97e1-ae46481dae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectoire_eligible_numerotation(trajectoires_eligibles):\n",
    "    trajectoires_eligibles.createOrReplaceTempView(\"trajectoires_eligibles\")\n",
    "    query = \"\"\"\n",
    "            select user, jour, trajectoire, avant_dernier_poi, dernier_poi,\n",
    "            row_number() over (partition by avant_dernier_poi, dernier_poi order by jour desc) as num\n",
    "            from trajectoires_eligibles        \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d01e4-63fa-42c3-b762-af1fb28a66b0",
   "metadata": {},
   "source": [
    "only one trajectory per suffix: the most recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0a86bfd7-1f93-4346-b8a0-f4b0db41ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectoire_eligible_par_suffixe(trajectoires_eligibles_num):\n",
    "    trajectoires_eligibles_num.createOrReplaceTempView(\"trajectoires_eligibles_num\")\n",
    "    query = \"\"\"\n",
    "            select  t.user, t.jour, t.trajectoire,avant_dernier_poi, dernier_poi\n",
    "            from trajectoires_eligibles_num t\n",
    "            where num=1\n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230811d-a24a-4d8c-9a96-e5db7adc6f68",
   "metadata": {},
   "source": [
    "#### Create train trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b3fff8a6-97e6-4c7b-9f5c-27a0c77b2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectoire_de_train(table_trajectoires_superieur_3, table_trajectoires_test):\n",
    "    table_trajectoires_superieur_3.createOrReplaceTempView(\"trajectoires_sup3\")\n",
    "    table_trajectoires_test.createOrReplaceTempView(\"traj_test\")\n",
    "    \n",
    "    \n",
    "    query = \"\"\"\n",
    "            select user, jour, trajectoire\n",
    "            from trajectoires_sup3\n",
    "            minus\n",
    "            select user, jour, trajectoire\n",
    "            from \n",
    "            traj_test;\n",
    "            \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b1823-02ac-45e6-a533-e26e737e0bcf",
   "metadata": {},
   "source": [
    "#### get test and train  set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5b0d2b77-faf8-47cd-a4b7-fba7944c09e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_or_create_testset_and_trainset(PUBLIC_DATASET_URL, yfcc_web_dir, local_dir, yfcc_file, n):\n",
    "    \n",
    "    test_set_file = local_dir + \"/\" + yfcc_file + f\"_M_{n}_testset\"\n",
    "    train_set_file = local_dir + \"/\" + yfcc_file + f\"_M_{n}_trainset\"\n",
    "    \n",
    "    if not ( os.path.exists(test_set_file) and  os.path.exists(train_set_file) ) :\n",
    "        yfcc_web_dir_download_URL = PUBLIC_DATASET_URL + \"/download?path=\" + \"/\" + yfcc_web_dir\n",
    "        get_yfcc_dataset(yfcc_web_dir_download_URL , local_dir, yfcc_file)\n",
    "\n",
    "        yfcc = lire_yfcc(yfcc_file)\n",
    "        visite1 = visite(yfcc)visiteRound = visit_round_to_n_meters(visite1, n)\n",
    "        frequence = lat_long_freq(visiteRound)\n",
    "        latlongFrance = bounding_box_France(frequence)\n",
    "        table_avec_num_POI = numorer_POI(latlongFrance)\n",
    "        table_visite_avec_num_POI = visiteNum(table_avec_num_POI, visiteRound)\n",
    "        traj_toutes_tailles = toutes_tailles_trajectoires(table_visite_avec_num_POI)\n",
    "        trajectoires_superieur_3 = trajectoires_sup3(traj_toutes_tailles)\n",
    "        trajectoires_eligibles = trajectoire_eligible(trajectoires_superieur_3)\n",
    "        trajectoires_eligibles_num = trajectoire_eligible_numerotation(trajectoires_eligibles)\n",
    "        trajectoires_eligibles_num = trajectoire_eligible_numerotation(trajectoires_eligibles)\n",
    "        trajectoire_test = trajectoire_eligible_par_suffixe(trajectoires_eligibles_num)\n",
    "        trajectoires_train = trajectoire_de_train(trajectoires_superieur_3, trajectoire_test)\n",
    "        \n",
    "        # write trajectoire_test\n",
    "        trajectoire_test.write.mode(\"overwrite\").format(\"parquet\").save(test_set_file)\n",
    "        trajectoires_train.write.mode(\"overwrite\").format(\"parquet\").save(train_set_file)   \n",
    "    else:\n",
    "        print(\"test set or train set already exist\")\n",
    "        \n",
    "    return spark.read.format(\"parquet\").load(test_set_file).persist(), spark.read.format(\"parquet\").load(train_set_file).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129f546-1247-406d-84f7-ff6b8ac88e2a",
   "metadata": {},
   "source": [
    "#### Length of all the trajectories (sup3, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c7a3871a-a527-4bb1-a0eb-38f30f7bbac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maillage</th>\n",
       "      <th>nombre_poi_france</th>\n",
       "      <th>nombre_trajectoire_sup3</th>\n",
       "      <th>nombre_trajectories_test</th>\n",
       "      <th>nombre_trajectoires_train</th>\n",
       "      <th>longueur_moyenne_seq_test_par_maillage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>473296</td>\n",
       "      <td>65731</td>\n",
       "      <td>235</td>\n",
       "      <td>65422</td>\n",
       "      <td>4.970213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>326923</td>\n",
       "      <td>65491</td>\n",
       "      <td>863</td>\n",
       "      <td>64535</td>\n",
       "      <td>6.028969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>266331</td>\n",
       "      <td>64373</td>\n",
       "      <td>1602</td>\n",
       "      <td>62671</td>\n",
       "      <td>5.865169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>194579</td>\n",
       "      <td>60870</td>\n",
       "      <td>3007</td>\n",
       "      <td>57766</td>\n",
       "      <td>5.371467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>142211</td>\n",
       "      <td>54833</td>\n",
       "      <td>3900</td>\n",
       "      <td>50798</td>\n",
       "      <td>4.766923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maillage  nombre_poi_france  nombre_trajectoire_sup3  \\\n",
       "0        10             473296                    65731   \n",
       "1        40             326923                    65491   \n",
       "2        70             266331                    64373   \n",
       "3       150             194579                    60870   \n",
       "4       300             142211                    54833   \n",
       "\n",
       "   nombre_trajectories_test  nombre_trajectoires_train  \\\n",
       "0                       235                      65422   \n",
       "1                       863                      64535   \n",
       "2                      1602                      62671   \n",
       "3                      3007                      57766   \n",
       "4                      3900                      50798   \n",
       "\n",
       "   longueur_moyenne_seq_test_par_maillage  \n",
       "0                                4.970213  \n",
       "1                                6.028969  \n",
       "2                                5.865169  \n",
       "3                                5.371467  \n",
       "4                                4.766923  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_toutes_valeurs_compt = []\n",
    "for n in P.maillage:\n",
    "    yfcc = lire_yfcc(P.yfcc_file)\n",
    "    visite1 = visite(yfcc)\n",
    "    visiteRound = visit_round_to_n_meters(visite1, n)\n",
    "    frequence = lat_long_freq(visiteRound)\n",
    "    \n",
    "    latlongFrance = bounding_box_France(frequence)\n",
    "    nombre_poi_france = latlongFrance.count()\n",
    "    \n",
    "    table_avec_num_POI = numorer_POI(latlongFrance)\n",
    "    table_visite_avec_num_POI = visiteNum(table_avec_num_POI, visiteRound)\n",
    "    traj_toutes_tailles = toutes_tailles_trajectoires(table_visite_avec_num_POI)\n",
    "    \n",
    "    trajectoires_superieur_3 = trajectoires_sup3(traj_toutes_tailles)\n",
    "    nombre_trajectories_sup3 = trajectoires_superieur_3.count()\n",
    "    \n",
    "    trajectoires_eligibles = trajectoire_eligible(trajectoires_superieur_3)\n",
    "    trajectoires_eligibles_num = trajectoire_eligible_numerotation(trajectoires_eligibles)\n",
    "\n",
    "    trajectoire_test = trajectoire_eligible_par_suffixe(trajectoires_eligibles_num)\n",
    "    nombre_trajectories_test = trajectoire_test.count()\n",
    "\n",
    "    trajectoires_train = trajectoire_de_train(trajectoires_superieur_3, trajectoire_test)\n",
    "    nombre_trajectoires_train = trajectoires_train.count()\n",
    "\n",
    "    longueur_moyenne_traj_test = (trajectoire_test.select(\"trajectoire\").withColumn(\"longueur\", f.size(\"trajectoire\"))).agg(f.avg(\"longueur\").alias(\"longueur_moyenne\"))\n",
    "    longueur_moyenne_traj_test_pandas = longueur_moyenne_traj_test.toPandas()\n",
    "    longueur_moyenne_traj_test_par_maillage = longueur_moyenne_traj_test_pandas[\"longueur_moyenne\"][0]\n",
    "\n",
    "    tuple_taille_traj_par_maillage = (n, nombre_poi_france, nombre_trajectories_sup3, nombre_trajectories_test, nombre_trajectoires_train, longueur_moyenne_traj_test_par_maillage)\n",
    "    liste_toutes_valeurs_compt.append(tuple_taille_traj_par_maillage)\n",
    "    \n",
    "columns=['maillage','nombre_poi_france','nombre_trajectoire_sup3','nombre_trajectories_test','nombre_trajectoires_train','longueur_moyenne_seq_test_par_maillage'] \n",
    "nbr_traj_train_test= pd.DataFrame(liste_toutes_valeurs_compt, columns = columns)\n",
    "nbr_traj_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8be89-0a5f-48f3-82e6-29df964feac8",
   "metadata": {},
   "source": [
    "#### Execute the creation of the test sets and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "821a61c6-d218-40cd-a41f-84b600fe7b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL du dossier contenant les datasets  https://nuage.lip6.fr/s/H3bpyRGgnCq2NR4\n",
      "10\n",
      "test set or train set already exist\n",
      "40\n",
      "test set or train set already exist\n",
      "70\n",
      "test set or train set already exist\n",
      "150\n",
      "test set or train set already exist\n",
      "300\n",
      "/local/jarrad/bd//yfccFrance.zip is already stored\n",
      "file already unziped\n"
     ]
    }
   ],
   "source": [
    "print(\"URL du dossier contenant les datasets \", P.PUBLIC_DATASET_URL)\n",
    "for m in P.maillage:\n",
    "    print(m)\n",
    "    trajectoires_test, trajectoires_train = get_or_create_testset_and_trainset(P.PUBLIC_DATASET_URL, P.yfcc_web_dir, P.local_dir, P.yfcc_file, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2f11c-c350-45f6-aac4-5d8bc9416574",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20997f63-54a1-42ae-8625-632322390396",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "63689b02-187c-4c34-b951-6b513c7e2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_trajectoires(trajectoires_train): \n",
    "    input_trajectoires_1 = trajectoires_train.selectExpr(\"trajectoire\")\n",
    "    input_trajectoires = [ [str(poi) for poi in t.trajectoire] for t in input_trajectoires_1.collect()]\n",
    "    \n",
    "    return input_trajectoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "62642459-2fbe-4f32-a5dc-552c129128ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name_dim(model_name, dimension, epoch, window):\n",
    "    return model_name + \"_dimension\" + str(dimension) + \"_epoch\" +str(epoch)+ \"_window\" +str(window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e6261f66-7f4f-4f57-8790-3c1941e5d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_model(trajectoires_train, model_name, expe_dimensions, expe_epochs, expe_windows):\n",
    "\n",
    "    input_trajectoires = get_input_trajectoires(trajectoires_train)\n",
    "    for dimension in expe_dimensions:\n",
    "        for epoch in expe_epochs:\n",
    "            for window in expe_windows:\n",
    "    \n",
    "                model_to_save = get_model_name_dim(model_name, dimension, epoch, window)\n",
    "                #si le modele n'existe pas deja\n",
    "                if not os.path.exists(model_to_save) :\n",
    "                    model = Word2Vec(sentences=input_trajectoires, vector_size=dimension, epochs =epoch, window=window, min_count=1, workers=64)\n",
    "                    model.save(model_to_save)\n",
    "                    print(\"model_saved\" , model_to_save)\n",
    "                else:\n",
    "                    print(\"model already exists\" , model_to_save)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f38577-af50-42f0-a796-5d6934806751",
   "metadata": {},
   "source": [
    "### Execute models creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5d6c5863-c354-4ab2-ab36-f429ae6f940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "test set or train set already exist\n",
      "model_saved /local/jarrad/bd/model_dimension/model_M10_dimension20_epoch100_window5\n",
      "model already exists /local/jarrad/bd/model_dimension/model_M10_dimension25_epoch100_window5\n",
      "40\n",
      "test set or train set already exist\n",
      "model_saved /local/jarrad/bd/model_dimension/model_M40_dimension20_epoch100_window5\n",
      "model already exists /local/jarrad/bd/model_dimension/model_M40_dimension25_epoch100_window5\n",
      "70\n",
      "test set or train set already exist\n",
      "model_saved /local/jarrad/bd/model_dimension/model_M70_dimension20_epoch100_window5\n",
      "model already exists /local/jarrad/bd/model_dimension/model_M70_dimension25_epoch100_window5\n",
      "150\n",
      "test set or train set already exist\n",
      "model_saved /local/jarrad/bd/model_dimension/model_M150_dimension20_epoch100_window5\n",
      "model already exists /local/jarrad/bd/model_dimension/model_M150_dimension25_epoch100_window5\n",
      "300\n",
      "test set or train set already exist\n",
      "model_saved /local/jarrad/bd/model_dimension/model_M300_dimension20_epoch100_window5\n",
      "model_saved /local/jarrad/bd/model_dimension/model_M300_dimension25_epoch100_window5\n"
     ]
    }
   ],
   "source": [
    "for m in P.maillage:\n",
    "    model_name = P.model_name + f\"_M{m}\"\n",
    "    print(m)\n",
    "    trajectoires_test, trajectoires_train = get_or_create_testset_and_trainset(P.PUBLIC_DATASET_URL, P.yfcc_web_dir, P.local_dir, P.yfcc_file, m)\n",
    "    dimension_model(trajectoires_train, model_name, P.expe_dimensions, P.expe_epochs, P.expe_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e57ccf-1fb3-4686-be62-be626ab172ab",
   "metadata": {},
   "source": [
    "# Prediction algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35286e91-8d7a-43a7-91b1-2a346846b03d",
   "metadata": {},
   "source": [
    "## similarity between trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "144e225c-2a95-41fe-979c-a6750c672479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarite_trajectoires_JACCARD(traj_test, trajectoire):\n",
    "    s1 = set(traj_test[:-1])\n",
    "    s2 = set(trajectoire[:-1])\n",
    "    sim = len(s1.intersection(s2)) / len(s1.union(s2))\n",
    "    return sim\n",
    "\n",
    "\n",
    "# Mean reciprocal rank MRR\n",
    "def similarite_trajectoires_MRR(traj_test, trajectoire):\n",
    "    somme = 0.0\n",
    "    for i in range(min(len(traj_test) , len(trajectoire))-1):\n",
    "        if traj_test[-2-i] == trajectoire[-2-i]:\n",
    "             somme += 1 / (i+1)    \n",
    "    return somme\n",
    "\n",
    "def load_w2v_model(model_name, dimension, epoch, window): \n",
    "    global MODEL\n",
    "    return MODEL   \n",
    "\n",
    "\n",
    "def similarite_trajectoires_JACCARD_cosinus(traj_test, trajectoire, model_name, dimension, epoch, window):\n",
    "    model = load_w2v_model( model_name, dimension, epoch, window)\n",
    "    somme = 0.0\n",
    "    for p1 in traj_test[:-1]:\n",
    "        try:\n",
    "            v1 = model.wv[str(p1)]\n",
    "            max_sim = -2\n",
    "            for p2 in trajectoire[:-1]:\n",
    "                v2 = model.wv[str(p2)]\n",
    "                sim = dot(v1, v2)/(norm(v1)*norm(v2))\n",
    "                #if sim > 0.6:\n",
    "                max_sim = max(max_sim, sim)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "        somme += max_sim\n",
    "            \n",
    "    return float(somme)\n",
    "def similarite_trajectoires_MRR_cosinus(traj_test, trajectoire, model_name, dimension, epoch, window):\n",
    "    model = load_w2v_model( model_name, dimension, epoch, window)\n",
    "    somme = 0.0\n",
    "    for i in range(min(len(traj_test) , len(trajectoire))-1):\n",
    "        try:\n",
    "            v1 = model.wv[str(traj_test[-2-i])]\n",
    "            max_sim = -2\n",
    "            for p2 in trajectoire[:-1]:\n",
    "                v2 = model.wv[str(p2)]\n",
    "                sim = dot(v1, v2)/(norm(v1)*norm(v2))\n",
    "                #if sim > 0.6:\n",
    "                max_sim = max(max_sim, sim)\n",
    "        except:\n",
    "            continue\n",
    "        somme += max_sim / (i+1)   \n",
    "    return float(somme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "167bbc95-3014-4a0d-8020-2eb4de7ebaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.sim_traj(traj_test, trajectoire_train, fct_similarite, model_name, dimension, epoch, window)>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sim_traj(traj_test, trajectoire_train, fct_similarite, model_name, dimension, epoch, window):\n",
    "    if fct_similarite==\"similarite_trajectoires_JACCARD\": \n",
    "        sim = similarite_trajectoires_JACCARD(traj_test, trajectoire_train)\n",
    "\n",
    "    elif fct_similarite==\"similarite_trajectoires_MRR\": \n",
    "        sim = similarite_trajectoires_MRR(traj_test, trajectoire_train)\n",
    "\n",
    "    elif fct_similarite==\"similarite_trajectoires_JACCARD_cosinus\": \n",
    "        sim = similarite_trajectoires_JACCARD_cosinus(traj_test, trajectoire_train, model_name, dimension, epoch, window)\n",
    "        \n",
    "    elif fct_similarite==\"similarite_trajectoires_MRR_cosinus\": \n",
    "        sim = similarite_trajectoires_MRR_cosinus(traj_test, trajectoire_train, model_name, dimension, epoch, window)\n",
    "    else:\n",
    "        print(\"erreur fonction inconnue\", fct_similarite)\n",
    "    return sim\n",
    "         \n",
    "spark.udf.register(\"sim_traj\", sim_traj, DoubleType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467db7f-9998-47f4-a33f-1002231cbbee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## paires de trajectoires "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ccb7fd-3d1a-4a6c-8fd2-ed4f9d35f7f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## pairs of trajectories \n",
    "test/train that have the LAST POI in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5e6ca4b5-2076-4bf2-80fb-1209c3c09ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paire_trajectoires(table_traj_train, table_traj_test):\n",
    "    table_traj_train.createOrReplaceTempView(\"traj_de_train\")\n",
    "    table_traj_test.createOrReplaceTempView(\"traj_de_test\")\n",
    "  \n",
    "    \n",
    "    query = f\"\"\"\n",
    "           SELECT test.trajectoire as traj_test, \n",
    "                  train.trajectoire as traj_train\n",
    "            FROM traj_de_test test , traj_de_train train\n",
    "            WHERE element_at(test.trajectoire, -2) = element_at(train.trajectoire, -2) \n",
    "            ;\n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d5e7c9fb-ffcd-4707-850d-c67ad527ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experience 3 : Toutes les trajectories train/test qui ont au moins 1 point en commun à n'importe quelle position\n",
    "\n",
    "#def paire_trajectoires(table_traj_train, table_traj_test):\n",
    "#    table_traj_train.createOrReplaceTempView(\"traj_de_train\")\n",
    "#    table_traj_test.createOrReplaceTempView(\"traj_de_test\")\n",
    "\n",
    "#    query = f\"\"\"\n",
    "#           SELECT test.trajectoire as traj_test, \n",
    "#                  train.trajectoire as traj_train\n",
    "#            FROM traj_de_test test , traj_de_train train\n",
    "#            WHERE intersection_entre_trajectoires(test.trajectoire, train.trajectoire) >0\n",
    "#            ;\n",
    "#            \"\"\"\n",
    "#    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a9347-0dee-4647-8fc1-7e0896b0d068",
   "metadata": {},
   "source": [
    "## Trajctories ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97adee8-f601-4103-98eb-2763135f19b3",
   "metadata": {},
   "source": [
    "For each test trajectory, ranking of training trajectories by decreasing similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8bb0fdcc-14e4-4356-8ae3-86ef8af830ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classement_trajectoires(table_paires_trajectoires, fonction_similarite, dimension, model_name, epoch, window):\n",
    "    table_paires_trajectoires.createOrReplaceTempView(\"table_paires_trajectoire\")\n",
    "    \n",
    "    \n",
    "    query = f\"\"\"\n",
    "            select *, sim_traj(traj_test, traj_train, {fonction_similarite}, '{model_name}', {dimension} , {epoch}, {window}) as similarite,\n",
    "            rank() over( partition by traj_test order by sim_traj(traj_test, traj_train, {fonction_similarite}, '{model_name}', {dimension}, {epoch}, {window} ) desc) as classement\n",
    "            from table_paires_trajectoire\n",
    "            order by traj_test, similarite desc;\n",
    "            \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4029cdbf-ac7c-4de3-8100-9d9d090d3e82",
   "metadata": {},
   "source": [
    "Group the TOP k most similar trajectories (for each test trajectory) by last train POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0782544f-4274-4a94-98de-32e80edc73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classement_top_k_traj_les_plus_sim(table_classement_des_trajectoires_par_sim, k):\n",
    "    table_classement_des_trajectoires_par_sim.createOrReplaceTempView(\"similarite_par_trajectoire_par_dernier_POI_du_train\") \n",
    "    query = f\"\"\"\n",
    "            select traj_test, element_at(traj_train, -1) as dernier_poi_train, sum(similarite) as similarite\n",
    "            from similarite_par_trajectoire_par_dernier_POI_du_train\n",
    "            where classement <= {k}\n",
    "            group by traj_test, element_at(traj_train, -1)\n",
    "            order by traj_test, similarite desc            \n",
    "            \"\"\" \n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c7997-d560-4a59-afa8-a4f8f7657fab",
   "metadata": {},
   "source": [
    "## Best score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67127fc-2fa2-43a4-9406-137b9e0ddfcd",
   "metadata": {},
   "source": [
    "keep only the prediction with the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e6255431-9798-4f13-8a28-0d4df4bd6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_avec_meilleur_score(table_top_k_classement_traj_similaires):\n",
    "    table_top_k_classement_traj_similaires.createOrReplaceTempView(\"trajectoire_avec_prediction\")\n",
    "    \n",
    "    \n",
    "    query = \"\"\"\n",
    "\n",
    "            select traj_test, element_at(array_sort(collect_list( (similarite, dernier_poi_train))), -1) as prediction\n",
    "            from trajectoire_avec_prediction\n",
    "            group by traj_test;\n",
    "    \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9601af43-9523-4017-a93a-0ccd9c6b9617",
   "metadata": {},
   "source": [
    "## prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6ce89a72-1d30-4201-97c7-4e834bf8a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(table_prediction_meilleur_score):\n",
    "    table_prediction_meilleur_score.createOrReplaceTempView(\"trajectoire_avec_meilleure_prediction\")\n",
    "    \n",
    "    \n",
    "    query = \"\"\"\n",
    "\n",
    "            select traj_test, element_at(traj_test, -1) as testPOI, prediction.dernier_poi_train as prediction\n",
    "            from trajectoire_avec_meilleure_prediction;\n",
    "    \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6531c7-7037-4dd3-b61d-aa4c49f24478",
   "metadata": {},
   "source": [
    "## prediction success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "772ab5a4-e57c-416e-beac-882355a18647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taux_succes_prediction(table_prediction):\n",
    "    table_prediction.createOrReplaceTempView(\"prediction_point\")\n",
    "   \n",
    "   \n",
    "   \n",
    "    query1 = \"\"\"\n",
    "           \n",
    "            select count(*)  as nb from prediction_point where testPOI = prediction;\n",
    "\n",
    "            \"\"\"\n",
    "   \n",
    "    query2 = \"\"\"select count(*)  as nb from prediction_point \"\"\"\n",
    "   \n",
    "    succes = spark.sql(query1)\n",
    "    succes_pandas = succes.toPandas()\n",
    "    success = succes_pandas[\"nb\"][0]\n",
    "    #print(success)\n",
    "   \n",
    "    total = spark.sql(query2)\n",
    "    total_pandas = total.toPandas()\n",
    "    totall = total_pandas[\"nb\"][0]\n",
    "    #print(totall)\n",
    "   \n",
    "    return success/totall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d07ec-4481-4ca2-a10d-a2a5b74ca438",
   "metadata": {},
   "source": [
    "# EXPERIENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d90ac77-17b0-44f3-9738-02cb560bf6e4",
   "metadata": {},
   "source": [
    "## Configurable experiences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d6a87-c0f9-4701-8b11-52af4acd79c2",
   "metadata": {},
   "source": [
    "## Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "441dcb64-1da6-44fa-b710-ea80e6f52440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesure_qualite(paires_avec_similarite_decroissante, k):\n",
    "    top_k_classement_traj_similaires = classement_top_k_traj_les_plus_sim(paires_avec_similarite_decroissante, k)\n",
    "    prediction_avec_meilleur_score = pred_avec_meilleur_score(top_k_classement_traj_similaires)\n",
    "    table_prediction = prediction(prediction_avec_meilleur_score)\n",
    "    taux = taux_succes_prediction(table_prediction)\n",
    "    return taux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ff7d0a2a-d5e0-4200-b492-f4d3f6fcf936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toutes_experiences(expe_topk, expe_dimensions,expe_epochs, model_name, experiment_dir, expe_maillage, expe_windows):\n",
    "    global MODEL\n",
    "\n",
    "    # name of the file in which the results of experiments based on embeddings are stored\n",
    "    def get_expe_vector_filemane(i):\n",
    "        return  experiment_dir + \"/\" + f\"expe_{i}_vectors.csv\"\n",
    "    \n",
    "    \n",
    "    # name of the file in which the results of experiments non based embeddings are stored\n",
    "    def get_expe_no_vector_filemane(i):\n",
    "        return  experiment_dir + \"/\" + f\"expe_{i}_no_vectors.csv\"\n",
    "    \n",
    "    file_num=1\n",
    "    while os.path.exists(get_expe_vector_filemane(file_num)) or os.path.exists(get_expe_no_vector_filemane(file_num)):\n",
    "        file_num = file_num + 1\n",
    "    with open(get_expe_vector_filemane(file_num), 'a') as f:\n",
    "        print(\"resultats expe avec vecteurs W2V dans :\",experiment_dir + get_expe_vector_filemane(file_num))\n",
    "        f.write('maillage,k,dimension,epoch,window,fonction de similarite,qualite\\n')\n",
    "        \n",
    "    with open(get_expe_no_vector_filemane(file_num), 'a') as f_sans_model:\n",
    "        print(\"resultats expe sans vecteurs dans :\",experiment_dir + get_expe_no_vector_filemane(file_num))\n",
    "        f_sans_model.write('maillage,k,dimension,epoch,window,fonction de similarite,qualite\\n')\n",
    "        \n",
    "    \n",
    "    for m in P.maillage:\n",
    "        trajectoires_test, trajectoires_train = get_or_create_testset_and_trainset(P.PUBLIC_DATASET_URL, P.yfcc_web_dir, P.local_dir, P.yfcc_file, m)\n",
    "        paires = paire_trajectoires(trajectoires_train, trajectoires_test)\n",
    "        paires.persist()\n",
    "        \n",
    "        \n",
    "        # with embeddings\n",
    "        with open(get_expe_vector_filemane(file_num), 'a') as f:\n",
    "            for dimension in expe_dimensions:\n",
    "                for epoch in expe_epochs:\n",
    "                    for window in expe_windows:\n",
    "                        model_name = P.model_name + f\"_M{m}\"\n",
    "                        model_to_load = get_model_name_dim(model_name, dimension, epoch, window)\n",
    "                        MODEL = Word2Vec.load(model_to_load)\n",
    "                        spark.udf.register(\"sim_traj\", sim_traj, DoubleType())\n",
    "                        for fonction_similarite in ('\\\"similarite_trajectoires_MRR_cosinus\\\"', '\\\"similarite_trajectoires_JACCARD_cosinus\\\"'):\n",
    "                            paires_avec_sim = classement_trajectoires(paires, fonction_similarite, dimension, model_name, epoch, window)\n",
    "                            paires_avec_sim.persist()\n",
    "                            for k in expe_topk:\n",
    "                                qualite = mesure_qualite(paires_avec_sim, k)\n",
    "                                tuple_experience = (m, k, dimension, epoch, window, fonction_similarite, qualite)\n",
    "                                sep = ','\n",
    "                                f.write(str(m) +sep + str(k) + sep + str(dimension) + sep + str(epoch)+ sep + str(window) + sep + str(fonction_similarite) + sep + str(qualite) + '\\n')\n",
    "                                f.flush()\n",
    "\n",
    "                        \n",
    "    \n",
    "    \n",
    "        # without embeddings\n",
    "        with open(get_expe_no_vector_filemane(file_num), 'a') as f_sans_model:\n",
    "            for fonction_similarite in ('\\\"similarite_trajectoires_JACCARD\\\"', '\\\"similarite_trajectoires_MRR\\\"'):\n",
    "                # calculer la similarité + tri\n",
    "                paires_avec_sim = classement_trajectoires(paires, fonction_similarite, dimension, model_name, epoch, window)\n",
    "                paires_avec_sim.persist()\n",
    "\n",
    "                for k in expe_topk:\n",
    "                    qualite = mesure_qualite(paires_avec_sim, k)\n",
    "                    tuple_experience = (m,k, 0,0,0, fonction_similarite, qualite)\n",
    "                    sep = ','\n",
    "                    f_sans_model.write(str(m) + sep +str(k) + sep + \"0\" + sep + \"0\"+ sep + \"0\"+ sep +str(fonction_similarite) + sep + str(qualite) + '\\n')\n",
    "                    f_sans_model.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c4789-9a41-4e3a-b506-554409372126",
   "metadata": {},
   "source": [
    "## Lancer les expériences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "125c1edd-cdf6-45a3-a710-1a5cc1ecbb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-01 23:26:43.257976\n",
      "resultats expe avec vecteurs W2V dans : /home/jarrad/Bureau/notebook_sara/experiment//home/jarrad/Bureau/notebook_sara/experiment//expe_185_vectors.csv\n",
      "resultats expe sans vecteurs dans : /home/jarrad/Bureau/notebook_sara/experiment//home/jarrad/Bureau/notebook_sara/experiment//expe_185_no_vectors.csv\n",
      "test set or train set already exist\n",
      "test set or train set already exist\n",
      "test set or train set already exist\n",
      "test set or train set already exist\n",
      "test set or train set already exist\n",
      "2023-05-01 23:33:24.730624 duree: 0:06:41.472648\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "t1 = datetime.now()\n",
    "print(t1)\n",
    "\n",
    "toutes_experiences(expe_topk = P.expe_topk, expe_dimensions= P.expe_dimensions, expe_epochs=P.expe_epochs,model_name = P.model_name, experiment_dir=P.experiment_dir, expe_maillage=P.maillage, expe_windows=P.expe_windows)\n",
    "\n",
    "t2 = datetime.now()\n",
    "print(t2, \"duree:\", t2-t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
